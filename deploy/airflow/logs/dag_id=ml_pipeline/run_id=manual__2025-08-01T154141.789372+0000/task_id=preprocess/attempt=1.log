[2025-08-01T15:41:44.200+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-01T15:41:44.233+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ml_pipeline.preprocess manual__2025-08-01T15:41:41.789372+00:00 [queued]>
[2025-08-01T15:41:44.243+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ml_pipeline.preprocess manual__2025-08-01T15:41:41.789372+00:00 [queued]>
[2025-08-01T15:41:44.243+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-01T15:41:44.258+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): preprocess> on 2025-08-01 15:41:41.789372+00:00
[2025-08-01T15:41:44.269+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62 DeprecationWarning: This process (pid=219) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-01T15:41:44.268+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ml_pipeline', 'preprocess', 'manual__2025-08-01T15:41:41.789372+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/ml_pipeline.py', '--cfg-path', '/tmp/tmp0ja8i6xf']
[2025-08-01T15:41:44.271+0000] {standard_task_runner.py:64} INFO - Started process 228 to run task
[2025-08-01T15:41:44.271+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask preprocess
[2025-08-01T15:41:44.290+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-08-01T15:41:44.342+0000] {task_command.py:426} INFO - Running <TaskInstance: ml_pipeline.preprocess manual__2025-08-01T15:41:41.789372+00:00 [running]> on host 9b25a94ed79c
[2025-08-01T15:41:44.435+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ml_pipeline' AIRFLOW_CTX_TASK_ID='preprocess' AIRFLOW_CTX_EXECUTION_DATE='2025-08-01T15:41:41.789372+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-08-01T15:41:41.789372+00:00'
[2025-08-01T15:41:44.436+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-01T15:41:44.978+0000] {python.py:237} INFO - Done. Returned value was: ((array([[-1.11073033,  1.30608073, -0.67194688, ...,  0.        ,
         0.        ,  0.        ],
       [-0.6070719 , -0.36385758,  0.63441021, ...,  0.        ,
         0.        ,  1.        ],
       [ 0.5681311 , -0.41160554, -0.67194688, ...,  0.        ,
         1.        ,  0.        ],
       ...,
       [-0.52312883, -0.11922681,  0.51565047, ...,  0.        ,
         0.        ,  1.        ],
       [ 0.81996031, -0.24262738,  1.10944915, ...,  0.        ,
         0.        ,  1.        ],
       [-0.94284418, -0.47330582,  0.87192968, ...,  0.        ,
         0.        ,  1.        ]]), 3955     1
11150    0
5173     1
3017     1
2910     1
        ..
5734     0
5191     1
5390     0
860      1
7270     0
Name: deposit, Length: 8929, dtype: int64), (array([[ 1.99516331, -0.24324748, -1.26574556, ...,  0.        ,
         0.        ,  1.        ],
       [-0.27129961,  0.03052815,  0.04061153, ...,  0.        ,
         0.        ,  1.        ],
       [-0.52312883,  1.06486053, -0.19690794, ...,  0.        ,
         0.        ,  0.        ],
       ...,
       [ 0.98784645, -0.34029366, -1.26574556, ...,  0.        ,
         0.        ,  0.        ],
       [ 0.5681311 , -0.18681808, -0.43442741, ...,  0.        ,
         1.        ,  0.        ],
       [-0.6070719 ,  0.03331861, -1.14698582, ...,  0.        ,
         0.        ,  0.        ]]), 5527     0
4541     1
1964     1
5007     1
8928     0
        ..
376      1
5544     0
10749    0
3881     1
6786     0
Name: deposit, Length: 2233, dtype: int64))
[2025-08-01T15:41:44.981+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-01T15:41:44.989+0000] {xcom.py:675} ERROR - Object of type tuple is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2025-08-01T15:41:44.991+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 91, in default
    return serialize(o)
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 150, in serialize
    return encode(classname or serialized_classname, version, serialize(data, depth + 1))
                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 127, in serialize
    return [serialize(d, depth + 1) for d in o]
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 150, in serialize
    return encode(classname or serialized_classname, version, serialize(data, depth + 1))
                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 127, in serialize
    return [serialize(d, depth + 1) for d in o]
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 189, in serialize
    raise TypeError(f"cannot serialize object of type {cls}")
TypeError: cannot serialize object of type <class 'numpy.ndarray'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 486, in _execute_task
    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3197, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 246, in set
    value = cls.serialize_value(
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 673, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 102, in encode
    o = self.default(o)
        ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 93, in default
    return super().default(o)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type tuple is not JSON serializable
[2025-08-01T15:41:45.001+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=ml_pipeline, task_id=preprocess, run_id=manual__2025-08-01T15:41:41.789372+00:00, execution_date=20250801T154141, start_date=20250801T154144, end_date=20250801T154145
[2025-08-01T15:41:45.014+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 3 for task preprocess (Object of type tuple is not JSON serializable; 228)
[2025-08-01T15:41:45.049+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2025-08-01T15:41:45.102+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-08-01T15:41:45.112+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
